{
 "metadata": {
  "name": "",
  "signature": "sha256:13df74636a3cfd0536cfa8a2b12176078d5bc8ecf841090f271cc31098d9fb60"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "title:  Regular expressions experiments\n",
      "slug: regex_experiments\n",
      "date: 2014-08-06 22:12\n",
      "tags: misc\n",
      "comments: true\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Experiments with [regular expressions](https://docs.python.org/2/library/re.html). A good introduction is available at [Google's Python classes](https://developers.google.com/edu/python/regular-expressions?hl=fr). One can also look at the chapter into [Dive into Python](http://www.diveintopython.net/regular_expressions/index.html). An online regular expression tester is available [here](http://regex101.com/#python)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "   - a, X, 9, < -- ordinary characters just match themselves exactly. The meta-characters which do not match themselves because they have special meanings are: . ^ $ * + ? { [ ] \\ | ( ) (details below)\n",
      "   \n",
      "- . (a period) -- matches any single character except newline '\\n'\n",
      "- \\w -- (lowercase w) matches a \"word\" character: a letter or digit or underbar [a-zA-Z0-9_]. Note that although \"word\" is the mnemonic for this, it only matches a single word char, not a whole word. \\W (upper case W) matches any non-word character.\n",
      "- \\b -- boundary between word and non-word\n",
      "- \\s -- (lowercase s) matches a single whitespace character -- space, newline, return, tab, form [ \\n\\r\\t\\f]. \\S (upper case S) matches any non-whitespace character.\n",
      "- \\t, \\n, \\r -- tab, newline, return\n",
      "- \\d -- decimal digit [0-9] (some older regex utilities do not support but \\d, but they all support \\w and \\s)\n",
      "- ^ = start, $ = end -- match the start or end of the string\n",
      "- \\ -- inhibit the \"specialness\" of a character. So, for example, use \\. to match a period or \\\\ to match a slash. If you are unsure if a character has special meaning, such as '@', you can put a slash in front of it, \\@, to make sure it is treated just as a character.\n",
      "\n",
      "Things get more interesting when you use + and * to specify repetition in the pattern\n",
      "\n",
      "- \"+\" -- 1 or more occurrences of the pattern to its left, e.g. 'i+' = one or more i's\n",
      "- \"*\" -- 0 or more occurrences of the pattern to its left\n",
      "- \"?\" -- match 0 or 1 occurrences of the pattern to its left"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Testing emails\n",
      "We first create a file with a list of emails. The goal is to deign a simple regexp in order to check the validity of emails. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file tstmails.txt\n",
      "jf.bercher@esiee.fr\n",
      "jfb@mailinator.com\n",
      "daniel.courivaud@esiee.fr\n",
      "zorro.pancho@arizona-u.edu\n",
      "tEsT@domain.info\n",
      "test@my-domain.info\n",
      "test@my-domain.information\n",
      "de-quoi-je-me-m\u00e8le@adresse.org"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting tstmails.txt\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first idea is just to check that an email has the structure \"name@domain.ext\". Then one can refine the test by noting that name and domain are composed of standard (not extended) ascii characters, plus the \".\", \"_\" and \"-\". (without \".\" for the domain part). Furthermore, the ext  has a length between 1 and 4. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "mail=re.compile(\"\\w+@\\w+\\.\\w{1,4}\")\n",
      "mail2=re.compile(r\"\"\"\n",
      "                 [\\w.-]+ #an alphanumeric character [a-zA-Z0-9_] plus . and -\n",
      "                 @ # the @\n",
      "                 [\\w-]+ #an alphanumeric character [a-zA-Z0-9_] plus  -\n",
      "                 \\. # a .\n",
      "                 \\w{1,4} # between one and 4 characters\n",
      "                 $ # end of string\n",
      "                 \"\"\",re.ASCII|re.VERBOSE)\n",
      "                \n",
      "with open('tstmails.txt') as f: \n",
      "    mails=f.readlines()\n",
      "    print(\"-\"*42)\n",
      "print(\"With 1st test\")\n",
      "print(\"-\"*42)\n",
      "for tst in mails:\n",
      "    if mail.match(tst):\n",
      "        print(\"{0:<32s} --- MATCHED\".format(tst[:-1]))\n",
      "    else:\n",
      "        print(\"{0:<32s} --- NOT MATCHED\".format(tst[:-1]))\n",
      "print(\"-\"*42)\n",
      "print(\"With 2nt test\")\n",
      "print(\"-\"*42)\n",
      "for tst in mails:\n",
      "    if mail2.match(tst):\n",
      "        print(\"{0:<32s} --- MATCHED\".format(tst[:-1]))\n",
      "    else:\n",
      "        print(\"{0:<32s} --- NOT MATCHED\".format(tst[:-1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Looking for and extracting components of a date "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a=!date "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "['mardi 12 ao\u00fbt 2014, 17:09:40 (UTC+0200)']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out=re.search(\"\\d{2}:\\d{2}:\\d{2}\",a[0])\n",
      "#print(dir(out))\n",
      "print(\"Result of first regexp: \",out.group(0))\n",
      "out=re.search(\"(\\d{2}):(\\d{2}):(\\d{2})\",a[0])\n",
      "print(\"Result of second regexp: \",out.group(0), \"\\n\", \"group 1: \", out.group(1), \"group 3: \",out.group(3))\n",
      "# with named groups\n",
      "out=re.search(\"(?P<hours>\\d{2}):(?P<minutes>\\d{2}):(?P<seconds>\\d{2})\",a[0])\n",
      "print(\"Result of third regexp: \",out.group(0), \"\\n\", \"hour: \", out.group('hours'), \"minutes: \",out.group('minutes'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Result of first regexp:  17:03:01\n",
        "Result of second regexp:  17:03:01 \n",
        " group 1:  17 group 3:  01\n",
        "Result of third regexp:  17:03:01 \n",
        " hour:  17 minutes:  03\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we test the `findall` version for extracting all the timestamps of a text."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt=\"Nuon Chea est d'\u00e9vidence, apr\u00e8s la mort de Pol Pot, le 15 avril 1998, celui que la justice pouvait consid\u00e9rer le plus directement 17:21:35 responsable dans l'\u00e9laboration des rouages de la machine de mort mise en place au Cambodge apr\u00e8s la chute de Phnom Penh aux 17:24:30 mains des Khmers rouges, le 17 avril 1975. \u00ab On peut se demander si Nuon Chea, le \u201cfr\u00e8re num\u00e9ro deux\u201d, n'\u00e9tait pas presque aussi important que le \u201cfr\u00e8re num\u00e9ro un\u201d [Pol Pot] \u00bb, avance m\u00eame l'historien Henri Locard dans son livre Pourquoi les Khmers rouges ? (\u00e9ditions Vend\u00e9miaire, 2013). Selon lui, 18:20:05 le couple Pol-Nuon formait comme une \u00ab hydre \u00e0 deux t\u00eates\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out=re.search(\"(?P<hours>\\d{2}):(?P<minutes>\\d{2}):(?P<seconds>\\d{2})\",txt)\n",
      "print(\"Result: \",out.group(0), \"\\n\", \"hour: \", out.group('hours'), \"minutes: \",out.group('minutes'),\"secondes: \",out.group('seconds'))\n",
      "\n",
      "hours=re.compile(\"(?P<hours>\\d{2}):(?P<minutes>\\d{2}):(?P<seconds>\\d{2})\")\n",
      "result=hours.findall(txt)\n",
      "for k,h in enumerate(result):\n",
      "    print(\"hours {0}: \".format(k), h[0],\"h \",h[1],\"m \",h[2],\"s\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Result:  17:21:35 \n",
        " hour:  17 minutes:  21 secondes:  35\n",
        "hours 0:  17 h  21 m  35 s\n",
        "hours 1:  17 h  24 m  30 s\n",
        "hours 2:  18 h  20 m  05 s\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Looking for the charset in an html file\n",
      "\n",
      "The charset can be found in html thanks to the tag `meta`\n",
      "- HTML5:   `<meta charset=\"UTF-8\">`\n",
      "- HTML4:   `<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">`\n",
      "     -  sometimes `<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Usin a regular expression\n",
      "def look_for_encoding(html):\n",
      "    import re\n",
      "    encoding = re.search(b'<meta\\s* http-equiv.*?charset=[\"\\']*(.+?)[\"\\'\\/]*>', html, flags=re.I)\n",
      "    if not encoding:\n",
      "        encoding = re.search(b'<meta.*?charset=[\"\\']*(.+?)[\"\\'\\/]*>', html, flags=re.I)\n",
      "        if not encoding:\n",
      "            encoding='utf8'\n",
      "    return encoding.group(1)            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Test**:\n",
      "- we give a (moderately) *difficult* html text -- from [here](http://www.r10.net/webmaster-genel-konular-sorunlar/993260-charsetiso-8859-9-charsetwindows-1254-charsetutf-8-kullanimi-hakkinda-yardim.html)\n",
      "- launch the `look_for_encoding` function on it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file html_encoding_tst.html\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"> <html xmlns=\"http://www.w3.org/1999/xhtml\" dir=\"ltr\" lang=\"tr\"> <head>\n",
      "<base href=\"http://www.r10.net/\"/><!--[if IE]></base><![endif]--> <meta property=\"og:image\" content=\"http://www.r10.net/ogmeta.jpg\"/> <meta itemprop=\"image\" content=\"http://www.r10.net/ogmeta.jpg\"> <script type=\"text/javascript\">\n",
      "//<![CDATA[\n",
      "try{if (!window.CloudFlare) {var CloudFlare=[{verbose:0,p:0,byc:0,owlid:\"cf\",bag2:1,mirage2:0,oracle:0,paths:{cloudflare:\"/cdn-cgi/nexp/dokv=88e434a982/\"},atok:\"1b6c1619cc6cd0bc2fb552cd582bec70\",petok:\"ddbe7bcfe5ba056091fa074d5173e3802d6ef986-1407230025-1800\",zone:\"r10.net\",rocket:\"m\",apps:{\"brwbl\":{\"a\":\"0\",\"brwbl\":\"38,38,40,40,37,39,37,39,66,65\"},\"abetterbrowser\":{\"ie\":\"7\"}}}];CloudFlare.push({\"apps\":{\"ape\":\"6781678d84514f25f701f9c595588ba7\"}});document.write('<script type=\"text/javascript\" src=\"//ajax.cloudflare.com/cdn-cgi/nexp/dokv=97fb4d042e/cloudflare.min.js\"><'+'\\/script>');}}catch(e){};\n",
      "//]]>\n",
      "</script>\n",
      "<link rel=\"image_src\" href=\"http://www.r10.net/ogmeta.jpg\"/> <meta property=\"og:title\" content=\"charset=iso-8859-9, charset=windows-1254, charset=utf-8&quot; kullan\u0131m\u0131 hakk\u0131nda yard\u0131m.\"/> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=ISO-8859-9\"/> <meta name=\"keywords\" content=\"charset,iso,8859,9,charset,windows,1254,charset,utf,8,quot,kullan\u0131m\u0131,hakk\u0131nda,yard\u0131m, charset=iso-8859-9, charset=windows-1254, charset=utf-8&quot; kullan\u0131m\u0131 hakk\u0131nda yard\u0131m., Google Webmaster forum,seo board, webmaster tools, wordpress adsense, google optimizasyon, dedicated server, hosting\"/> <meta name=\"description\" content=\"Arkada\u015flar \u00f6ncelikle merhaba, bir sorum olucak benim haber sitemde &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=iso-8859-9&quot; /&gt; yaz\u0131l\u0131mc\u0131 bunu kullan\u0131yor ancak\"/> \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting html_encoding_tst.html\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h=open('html_encoding_tst.html','rb')\n",
      "a=look_for_encoding(h.read())\n",
      "print(a) # a is  class bytes\n",
      "print(a.decode('ascii'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "b'ISO-8859-9'\n",
        "ISO-8859-9\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Messages parsing\n",
      "This example is taken from the course [Python: regular expressions](http://www.ucs.cam.ac.uk/docs/course-notes/unix-courses/PythonRE) at UIS - university of Cambridge. The goal is to extract the lines like\n",
      ">Jun 30 03:02:16 noether sshd[9515]: Invalid user gopher from 65.19.189.149\n",
      "\n",
      ">Jul 1 07:41:11 noether sshd[14506]: Invalid user test from 210.51.172.168\n",
      "\n",
      "of the log /var/log/messages of a workstation subjected to hackers attacks. We want not only to extract these lines, but also to keep the date, username and IP of the attempts, eg as a list of tuples.    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import sys\n",
      "\n",
      "pattern = r'''\n",
      "^\n",
      "([A-Z][a-z]{2})\\s+       # Month\n",
      "([123][0-9])\\s+       # Day\n",
      "(\\d\\d:\\d\\d:\\d\\d)\\         # Time\n",
      "noether\\s+  sshd\n",
      "\\[\\d+\\]:\\s+             # Process ID\n",
      "Invalid\\s+  user\\ \n",
      "(\\w+)                   # Fake user ID\n",
      "\\s+from\\s+\n",
      "(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})     # Host address\n",
      "$\n",
      "'''\n",
      "\n",
      "regexp = re.compile(pattern, re.IGNORECASE+re.VERBOSE)\n",
      "\n",
      "data = open('messages', 'r')\n",
      "k=0\n",
      "hacks=[]\n",
      "\n",
      "for line in data:\n",
      "    match = regexp.search(line)\n",
      "    #print(line)\n",
      "    \n",
      "    if match:\n",
      "       # print(line)\n",
      "        hacks.append((match.group(1)+' '+match.group(2)+' '+match.group(3),match.group(4),match.group(5)))\n",
      "\n",
      "print(hacks[:10])\n",
      "data.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Jun 25 23:47:33', 'account', '207.54.140.124'), ('Jun 25 23:47:34', 'adam', '207.54.140.124'), ('Jun 25 23:47:35', 'adi', '207.54.140.124'), ('Jun 25 23:47:36', 'adina', '207.54.140.124'), ('Jun 25 23:47:37', 'adm', '207.54.140.124'), ('Jun 25 23:47:41', 'admin', '207.54.140.124'), ('Jun 25 23:47:42', 'admin', '207.54.140.124'), ('Jun 25 23:47:43', 'admin', '207.54.140.124'), ('Jun 25 23:47:44', 'admin', '207.54.140.124'), ('Jun 25 23:47:45', 'adrian', '207.54.140.124')]\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is even much easier to just launch a `findall` over the whole file, instead of doing a loop and test over each line. It goes like this: \n",
      ">Note that we must use the MULTILINE flag, sice the regex pattern includes the ^ and $ string delimiters. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r'''\n",
      "^\n",
      "([A-Z][a-z]{2})\\s+       # Month\n",
      "([123][0-9])\\s+       # Day\n",
      "(\\d\\d:\\d\\d:\\d\\d)\\         # Time\n",
      "noether\\s+  sshd\n",
      "\\[\\d+\\]:\\s+             # Process ID\n",
      "Invalid\\s+  user\\ \n",
      "(\\w+)                   # Fake user ID\n",
      "\\s+from\\s+\n",
      "(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})     # Host address\n",
      "$\n",
      "'''\n",
      "data = open('messages', 'r')\n",
      "newregexp = re.compile(pattern, re.IGNORECASE+re.VERBOSE+re.MULTILINE)\n",
      "out=newregexp.findall(data.read())\n",
      "print(out[:10])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Jun', '25', '23:47:33', 'account', '207.54.140.124'), ('Jun', '25', '23:47:34', 'adam', '207.54.140.124'), ('Jun', '25', '23:47:35', 'adi', '207.54.140.124'), ('Jun', '25', '23:47:36', 'adina', '207.54.140.124'), ('Jun', '25', '23:47:37', 'adm', '207.54.140.124'), ('Jun', '25', '23:47:41', 'admin', '207.54.140.124'), ('Jun', '25', '23:47:42', 'admin', '207.54.140.124'), ('Jun', '25', '23:47:43', 'admin', '207.54.140.124'), ('Jun', '25', '23:47:44', 'admin', '207.54.140.124'), ('Jun', '25', '23:47:45', 'adrian', '207.54.140.124')]\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Substitution\n",
      "An interesting application is also to substitute things according to a regex. As an illustration, we look for a simple conversion of bold and italic tags in a makdown text. In [markdown](https://help.github.com/articles/markdown-basics), **bold** is indicated by `**bold**`or `__bold__` and *italic* by `*italic*` or `_italic_`. Therefore, the goal is to look for groups delimited by a pair of `*`, `**`, etc and then substitute them by another tagged version, e.g. an html tag. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt=\"\"\"This is a simple text in markdown, with **bold**, _italic_;\n",
      "            another __bold__ **and** *another italic*. \n",
      "The goal is to convert this into an html version.\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt=\"\"\"This is a simple text in markdown, with **bold**, _italic_;\n",
      "another __bold__ **and** *another italic*. \n",
      "The goal is to convert this into an _html_ version.\"\"\"\n",
      "import re\n",
      "p1='\\*\\*(?P<bf>.*)\\*\\*'\n",
      "p2='__(?P<bf>.*)__'\n",
      "p3='\\*(?P<it>.*)\\*'\n",
      "p4='_(?P<it>.*)_'\n",
      "txt=re.sub(p1,'<b>\\g<bf></b>',txt,re.M)\n",
      "txt=re.sub(p2,'<b>\\g<bf></b>',txt,re.M)\n",
      "txt=re.sub(p3,'<i>\\g<it></i>',txt,re.M)\n",
      "txt=re.sub(p4,'<i>\\g<it></i>',txt,re.M)\n",
      "print(txt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "This is a simple text in markdown, with <b>bold</b>, <i>italic</i>;\n",
        "another <b>bold</b> <b>and</b> <i>another italic</i>. \n",
        "The goal is to convert this into an <i>html</i> version.\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Without named groups, it is needed to escape the groups backreferences, otherwise they are interpreted as octal character code escapes. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt=\"\"\"This is a simple text in markdown, with **bold**, _italic_;\n",
      "another __bold__ **and** *another italic*. \n",
      "The goal is to convert this into an _html_ version.\"\"\"\n",
      "import re\n",
      "p1='\\*\\*(.*)\\*\\*'\n",
      "p2='__(.*)__'\n",
      "p3='\\*(.*)\\*'\n",
      "p4='_(.*)_'\n",
      "txt=re.sub(p1,'<b>\\\\1</b>',txt,re.M)\n",
      "txt=re.sub(p2,'<b>\\\\1</b>',txt,re.M)\n",
      "txt=re.sub(p3,'<i>\\\\1</i>',txt,re.M)\n",
      "txt=re.sub(p4,'<i>\\\\1</i>',txt,re.M)\n",
      "print(txt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "This is a simple text in markdown, with <b>bold</b>, <i>italic</i>;\n",
        "another <b>bold</b> <b>and</b> <i>another italic</i>. \n",
        "The goal is to convert this into an <i>html</i> version.\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a more efficient implementation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "txt=\"\"\"This is a simple text in markdown, with **bold**, _italic_;\n",
      "another __bold__ **and** *another italic*. \n",
      "The goal is to convert this into an _html_ version.\"\"\"\n",
      "import re\n",
      "p1='([_\\*]{1})(.*)\\\\1'\n",
      "p2='([_\\*]{2})(.*)\\\\1' # match a single character present in the list two times\n",
      "\n",
      "txt=re.sub(p2,'<i>\\\\2</i>',txt,re.M)\n",
      "txt=re.sub(p1,'<b>\\\\2</b>',txt,re.M)\n",
      "\n",
      "\n",
      "print(txt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "This is a simple text in markdown, with <i>bold</i>, <b>italic</b>;\n",
        "another <i>bold</i> <i>and</i> <b>another italic</b>. \n",
        "The goal is to convert this into an <b>html</b> version.\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### GPS location from a google-map page\n",
      "\n",
      "While it is possible to directly use Google's [Geocoding API](https://developers.google.com/maps/documentation/javascript/geocoding), or even a dedicated python module like [geopy](https://pypi.python.org/pypi/geopy). It is still amusing to extract the GPS location from a google maps webpage. This is easily done using a regex expression on the html response to a location request. This is the objective of the following script. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file coordGPS.py\n",
      "#!/usr/bin/env python3\n",
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "Created on May24, 2014\n",
      "Last updated on July 19, 2014\n",
      "@author: bercherj\n",
      "\"\"\"\n",
      " \n",
      "def coord(city,proxies={}):\n",
      "    \"\"\"\n",
      "    inputs:\n",
      "    ------ \n",
      "       city: string\n",
      "           name of the searched city \n",
      "    outputs:\n",
      "    ------- \n",
      "      latlng: tuple \n",
      "           GPS coordinates (lat, lng)\n",
      "\n",
      "    \"\"\"\n",
      "    import urllib.parse\n",
      "    import urllib.request\n",
      "    import re \n",
      "        \n",
      "    url = 'http://maps.google.fr/maps'\n",
      "    values = {'saddr' : str(city), \n",
      "              'f':'d'}\n",
      "    \n",
      "                   \n",
      "    proxy_handler = urllib.request.ProxyHandler(proxies)\n",
      "\n",
      "    opener = urllib.request.build_opener(proxy_handler)\n",
      "    \n",
      "    #opener = urllib.request.FancyURLopener(proxies)\n",
      "    response = opener.open(url+'/?'+urllib.parse.urlencode(values))\n",
      "    the_page = response.read().decode('latin1')\n",
      "    #the_page = response.read().decode('utf8')\n",
      "            \n",
      "    latlng=re.findall('latlng:{lat:([-0-9.]*),lng:([-0-9.]*)},',the_page)\n",
      "           \n",
      "    return latlng[0]\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\t    \n",
      "\timport argparse\n",
      "\n",
      "\twhatitdoes=\"This program returns the GPS location given the name of a city. It uses the information given by google maps.\"\n",
      "\tmyself=\"(c) JFB\"\n",
      "\tparser = argparse.ArgumentParser(description=whatitdoes, epilog=myself)\n",
      "\n",
      "\tparser.add_argument(\n",
      "\t# no option eg  '-o' '--output' # ==> mandatory argument\n",
      "\thelp = 'Name of cities to be processed',\n",
      "\tdest = 'cities',\n",
      "\tdefault = ['grenoble'],\n",
      "\ttype = str,\n",
      "\tnargs = '*'\n",
      "\t)\n",
      "\tparser.add_argument(\n",
      "\t'-v',\n",
      "\t'--verbose',\n",
      "\thelp = 'Prints information',\n",
      "\tdest = 'verbose',\n",
      "\tdefault = False,\n",
      "\taction='store_true'\n",
      "\t)\n",
      "\t\n",
      "\tparser.add_argument(\n",
      "\t'-p',\n",
      "\t'-proxy',\n",
      "\t'--proxy',\n",
      "\thelp = 'Takes proxy configuration from \"proxy.cfg\"',\n",
      "\tdest = 'proxy',\n",
      "\tdefault = False,\n",
      "\taction='store_true'\n",
      "\t)\n",
      "\t\n",
      "\n",
      "\targs = parser.parse_args()\n",
      "\tprint(args)\n",
      "\t\n",
      "\tproxies={}\n",
      "\tif args.proxy:\n",
      "\t\timport configparser\n",
      "\t\tconfig = configparser.ConfigParser()\n",
      "\t\ts=config.read('proxy.cfg')\n",
      "\t\tif s: #if the cfg file exists\n",
      "\t\t\tproxies=dict(config['proxies'])\n",
      "\tprint(proxies)\n",
      "\n",
      "\n",
      "\tfor city in list(args.cities):\n",
      "\t\tprint(city)\t\n",
      "\t\tll=coord(city,proxies)\n",
      "\t\tprint(city+\": Latitude: {0}, Longitude: {1}\".format(ll[0],ll[1]) )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting coordGPS.py\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run coordGPS.py -h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "usage: coordGPS.py [-h] [-v] [-p] [cities [cities ...]]\n",
        "\n",
        "This program returns the GPS location given the name of a city. It uses the\n",
        "information given by google maps.\n",
        "\n",
        "positional arguments:\n",
        "  cities               Name of cities to be processed\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help           show this help message and exit\n",
        "  -v, --verbose        Prints information\n",
        "  -p, -proxy, --proxy  Takes proxy configuration from \"proxy.cfg\"\n",
        "\n",
        "(c) JFB\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run coordGPS.py G\u00e9rone"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Namespace(cities=['G\u00e9rone'], proxy=False, verbose=False)\n",
        "{}\n",
        "G\u00e9rone\n",
        "G\u00e9rone: Latitude: 41.9794, Longitude: 2.821426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(the_end(theNotebook))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "    <small>\n",
        "    <p> This post was written as an IPython notebook.  It is available for\n",
        "    <a href=\"http://jfbercher.github.com/downloads/notebooks/regex_experiments.ipynb\">download</a> or as a static\n",
        "    <a href=\"http://nbviewer.ipython.org/url/jfbercher.github.com/downloads/notebooks/regex_experiments.ipynb\">html</a>.</p>\n",
        "    <p></p>\n",
        "    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img\n",
        "    alt=\"Creative Commons License\" style=\"border-width:0\"\n",
        "    src=\"http://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br /><span\n",
        "    xmlns:dct=\"http://purl.org/dc/terms/\"\n",
        "    property=\"dct:title\">jfblog</span> by <a\n",
        "    xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://jfbercher.github.io/\"\n",
        "    property=\"cc:attributionName\" rel=\"cc:attributionURL\">J.-F. Bercher</a> is\n",
        "    licensed under a <a rel=\"license\"\n",
        "    href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons\n",
        "    Attribution-ShareAlike 4.0 International License</a>.<br />Based on a work at <a\n",
        "    xmlns:dct=\"http://purl.org/dc/terms/\" href=\"http://jfbercher.github.io/\"\n",
        "    rel=\"dct:source\">http://jfbercher.github.io/</a>.\n",
        "        "
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x7f356ddf4fd0>"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}